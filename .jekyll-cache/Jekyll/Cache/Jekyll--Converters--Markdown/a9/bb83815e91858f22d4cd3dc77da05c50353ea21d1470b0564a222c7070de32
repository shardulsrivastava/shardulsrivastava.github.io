I"ËK<p>Kubernetes has become a de-factor standard because it takes care of a lot of complexities internally. One of those complexities is cluster autoscaling that is provisioning of nodes based on increased number of workloads.</p>

<p><a href="https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler">Cluster Autoscaler</a> is a project maintained by a community called <code class="language-html highlighter-rouge">sig-autoscaling</code>, one of the communities under <code class="language-html highlighter-rouge">Kubernetes</code>. Check out more about Kubernetes Communities <a href="https://github.com/kubernetes/community">here</a>.</p>

<p>Cluster autoscaler supports a number of <a href="https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler/cloudprovider">cloud providers</a> including EKS. <a href="https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler/cloudprovider/aws">here</a> is the guide to setup cluster autoscaler on EKS and various configuration <a href="https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler/cloudprovider/aws/examples">examples</a>.</p>

<p>Cluster autoscaler runs in the cluster as an addon and adds or removes the nodes in the cluster to allow scheduling of workloads. It kicks in when any of the pods is not able to schedule due to insufficient resources. Node groups in EKS are backed by <code class="language-html highlighter-rouge">EC2 Auto Scaling Groups</code> and CA updates the number of node in the ASG based on scale up or down. It also supports Mixed Instance policies for Spot instances that allowing users to save cost with Spot instances with the added risk of workload interruption.</p>

<p>While CA takes care of scaling efficiently, there are still issues that EKS users face such as :</p>

<ol>
  <li>When there are no instances in the Node group of matching requirements for the workload to be scheduled. It prints these messages in the logs:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pod didn<span class="s1">'t trigger scale-up (it wouldn'</span>t fit <span class="k">if </span>a new node is added<span class="o">)</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>Using too big instances in node groups, leading to low resources utilization hence incurring increase cost.</p>
  </li>
  <li>
    <p>Using too low instances in Node groups, leading to node groups maxing out and resulting into unscheduled pods.</p>
  </li>
  <li>No way to identify the optimal choice instance types based on workloads.</li>
</ol>

<p>All of these issues and many more can be solved withâ€¦</p>

<p><img src="/assets/images/karpenter.jpeg" alt="karpenter" /></p>

<h2 id="karpenter">Karpenter</h2>

<p><a href="https://karpenter.sh/">Karpenter</a> is an open source project by AWS that improves the efficiency and cost of running workloads on Kubernetes clusters. Itâ€™s group less i.e it works by provisioning nodes based on the workload and the nodes provisioned are not part of any ASG.</p>

<p>This allows Karpenter to scale nodes more efficiently and retry in a few miliseconds when node capacity is not available instead of waiting for minutes in case of an ASG and gives the flexibility to provision Instances from a variety of instance types without creating hundreds of node groups.</p>

<h2 id="karpenter-installation">Karpenter Installation</h2>

<p>Karpenter runs as a controller in the form of a deployment in the cluster and relies on a CRD called <a href="https://karpenter.sh/v0.17.0/provisioner/">Provisioner</a> for determine how to handle workloads such as consolidate them to save costs, move them to another node with a different instance type to save cost and  scale down nodes when they are empty.</p>

<h3 id="setup-an-eks-cluster-with-karpenter-enabled">Setup an EKS Cluster with Karpenter enabled</h3>

<p>Karpenter can be installed by following the steps in the <a href="https://karpenter.sh/v0.17.0/getting-started/getting-started-with-eksctl/">Getting Started Guide</a> which involved creating several Cloudformation stacks, IAM role cluster bindings. however simplest way to get started is to use <code class="language-html highlighter-rouge">eksctl</code> that supports out of box <code class="language-html highlighter-rouge">karpenter</code> installation.</p>

<p>Letâ€™s create a cluster with <code class="language-html highlighter-rouge">eksctl</code> with a managed node group and <code class="language-html highlighter-rouge">karpenter</code> installed:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">eksctl.io/v1alpha5</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ClusterConfig</span>

<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">karpenter-cluster</span>
  <span class="na">region</span><span class="pi">:</span> <span class="s">eu-west-1</span>
  <span class="na">version</span><span class="pi">:</span> <span class="s2">"</span><span class="s">1.22"</span>
  <span class="na">tags</span><span class="pi">:</span>
    <span class="na">karpenter.sh/discovery</span><span class="pi">:</span> <span class="s">karpenter-cluster</span> <span class="c1"># Special tag for Karpenter</span>
<span class="na">iam</span><span class="pi">:</span>
  <span class="na">withOIDC</span><span class="pi">:</span> <span class="no">true</span> <span class="c1"># required</span>

<span class="na">karpenter</span><span class="pi">:</span>
  <span class="na">version</span><span class="pi">:</span> <span class="s1">'</span><span class="s">0.15.0'</span>
  <span class="na">createServiceAccount</span><span class="pi">:</span> <span class="no">true</span> 

<span class="na">managedNodeGroups</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">managed-ng-1</span>
    <span class="na">minSize</span><span class="pi">:</span> <span class="m">1</span>
    <span class="na">maxSize</span><span class="pi">:</span> <span class="m">10</span>
    <span class="na">desiredCapacity</span><span class="pi">:</span> <span class="m">1</span>
    <span class="na">instanceType</span><span class="pi">:</span> <span class="s">t3.large</span>
    <span class="na">amiFamily</span><span class="pi">:</span> <span class="s">AmazonLinux2</span>
</code></pre></div></div>

<p>this would create a cluster <code class="language-html highlighter-rouge">karpenter-cluster</code> in <code class="language-html highlighter-rouge">eu-west-1</code> region with a managed Node group <code class="language-html highlighter-rouge">managed-ng-1</code> and couple of components for <code class="language-html highlighter-rouge">karpenter</code> to work:</p>

<ol>
  <li><code class="language-html highlighter-rouge">eksctl-KarpenterControllerPolicy-karpenter-cluster</code> - An <a href="https://github.com/aws/karpenter/blob/30a4a5af24fb065471c9ec1203db861d9eb45ac4/website/content/en/v0.15.0/getting-started/getting-started-with-eksctl/cloudformation.yaml#L34-L66">IAM policy</a> with permissions to provision nodes and spot instances.</li>
  <li><code class="language-html highlighter-rouge">eksctl-karpenter-cluster-iamservice-role</code> - An IAM role with IAM policy <code class="language-html highlighter-rouge">eksctl-KarpenterControllerPolicy-karpenter-cluster</code> and attached to the service account used by karpenter to allow it to provision instances.</li>
  <li><code class="language-html highlighter-rouge">eksctl-KarpenterNodeRole-karpenter-cluster</code> - An <a href="https://github.com/aws/karpenter/blob/30a4a5af24fb065471c9ec1203db861d9eb45ac4/website/content/en/v0.15.0/getting-started/getting-started-with-eksctl/cloudformation.yaml#L15-L33">IAM role</a> for provisioned nodes to work and get registered with the cluster.</li>
  <li><code class="language-html highlighter-rouge">eksctl-KarpenterNodeInstanceProfile-karpenter-cluster</code> - An <a href="https://github.com/aws/karpenter/blob/30a4a5af24fb065471c9ec1203db861d9eb45ac4/website/content/en/v0.15.0/getting-started/getting-started-with-eksctl/cloudformation.yaml#L8-L14">Instance profile</a> for instance provisioned by Karpenter.</li>
  <li><code class="language-html highlighter-rouge">karpenter Helm Release</code> - Installation of karpenter using <a href="https://github.com/aws/karpenter/tree/main/charts/karpenter">Helm chart</a>.</li>
</ol>

<p>Now we have <code class="language-html highlighter-rouge">karpenter</code> installed in the cluster.</p>

<h3 id="setup-karpenter-provisioner">Setup Karpenter Provisioner</h3>

<p>To configure Karpenter, you need to create a <a href="https://karpenter.sh/v0.17.0/provisioner/">Provisioner</a> resource that defines how Karpenter provisions nodes and deletes them. Karpenter has a number of configurations. Letâ€™s start with the basic Provisioner :</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">karpenter.sh/v1alpha5</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Provisioner</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">default</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">provider</span><span class="pi">:</span>
    <span class="na">subnetSelector</span><span class="pi">:</span>
      <span class="na">karpenter.sh/discovery</span><span class="pi">:</span> <span class="s">karpenter-cluster</span>
    <span class="na">securityGroupSelector</span><span class="pi">:</span>
      <span class="na">karpenter.sh/discovery</span><span class="pi">:</span> <span class="s">karpenter-cluster</span>
</code></pre></div></div>

<p>Here <code class="language-html highlighter-rouge">subnetSelector</code> and <code class="language-html highlighter-rouge">securityGroupSelector</code> values allow karpenter to discover subnets and security groups i.e karpenter would discover the subnets and security groups using these tags and create the node in one of these subnets and attach the discovered security groups to the node.</p>

<p>Letâ€™s create a sample <code class="language-html highlighter-rouge">Nginx</code> deployment with CPU request as <code class="language-html highlighter-rouge">1</code></p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">nginx</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">nginx</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">1</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">nginx</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">nginx</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">image</span><span class="pi">:</span> <span class="s">quay.io/shardul/nginx:v1</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">nginx</span>
        <span class="na">imagePullPolicy</span><span class="pi">:</span> <span class="s">Always</span>
        <span class="na">resources</span><span class="pi">:</span>
          <span class="na">requests</span><span class="pi">:</span>
            <span class="na">cpu</span><span class="pi">:</span> <span class="m">1</span>
</code></pre></div></div>

<p>Check if pods are running :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl get pods
</code></pre></div></div>
<p><img src="/assets/images/pod-pending.png" alt="pending pods" /></p>

<p>we can see that at first pod is pending, however then karpenter kicks in as evident from karpenter logs :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl <span class="nt">-n</span> karpenter logs <span class="nt">-f</span> <span class="nt">-l</span> app.kubernetes.io/instance<span class="o">=</span>karpenter <span class="nt">-c</span> controller

2022-10-09T15:35:31.066Z  INFO  controller.provisioning Computed 1 new node<span class="o">(</span>s<span class="o">)</span> will fit 1 pod<span class="o">(</span>s<span class="o">)</span>  <span class="o">{</span><span class="s2">"commit"</span>: <span class="s2">"3d87474"</span><span class="o">}</span>
2022-10-09T15:35:31.253Z  DEBUG controller.provisioning.cloudprovider Discovered subnets: <span class="o">[</span>subnet-0bb805312e46db35f <span class="o">(</span>eu-west-1b<span class="o">)</span> subnet-05bd621d69320799a <span class="o">(</span>eu-west-1c<span class="o">)</span> subnet-02828f6cf56a0eabc <span class="o">(</span>eu-west-1a<span class="o">)</span> subnet-0d94022cc49b76aeb <span class="o">(</span>eu-west-1a<span class="o">)</span> subnet-09ebfc5011dbf69fb <span class="o">(</span>eu-west-1b<span class="o">)</span> subnet-084a73ba681d60241 <span class="o">(</span>eu-west-1c<span class="o">)]</span> <span class="o">{</span><span class="s2">"commit"</span>: <span class="s2">"3d87474"</span>, <span class="s2">"provisioner"</span>: <span class="s2">"default"</span><span class="o">}</span>
2022-10-09T15:35:31.387Z  DEBUG controller.provisioning.cloudprovider Discovered security <span class="nb">groups</span>: <span class="o">[</span>sg-03a9dd659d9a0b8fd sg-00a2bf520128db45b] <span class="o">{</span><span class="s2">"commit"</span>: <span class="s2">"3d87474"</span>, <span class="s2">"provisioner"</span>: <span class="s2">"default"</span><span class="o">}</span>
2022-10-09T15:35:31.390Z  DEBUG controller.provisioning.cloudprovider Discovered kubernetes version 1.22  <span class="o">{</span><span class="s2">"commit"</span>: <span class="s2">"3d87474"</span>, <span class="s2">"provisioner"</span>: <span class="s2">"default"</span><span class="o">}</span>
2022-10-09T15:35:31.425Z  DEBUG controller.provisioning.cloudprovider Discovered ami-04f335c3e4d6dcfad <span class="k">for </span>query <span class="s2">"/aws/service/eks/optimized-ami/1.22/amazon-linux-2-arm64/recommended/image_id"</span>  <span class="o">{</span><span class="s2">"commit"</span>: <span class="s2">"3d87474"</span>, <span class="s2">"provisioner"</span>: <span class="s2">"default"</span><span class="o">}</span>
2022-10-09T15:35:31.446Z  DEBUG controller.provisioning.cloudprovider Discovered ami-0ed22cc46dcbf16ed <span class="k">for </span>query <span class="s2">"/aws/service/eks/optimized-ami/1.22/amazon-linux-2/recommended/image_id"</span>  <span class="o">{</span><span class="s2">"commit"</span>: <span class="s2">"3d87474"</span>, <span class="s2">"provisioner"</span>: <span class="s2">"default"</span><span class="o">}</span>
2022-10-09T15:35:31.483Z  DEBUG controller.provisioning.cloudprovider Discovered launch template Karpenter-karpenter-cluster-5093968976540638239  <span class="o">{</span><span class="s2">"commit"</span>: <span class="s2">"3d87474"</span>, <span class="s2">"provisioner"</span>: <span class="s2">"default"</span><span class="o">}</span>
2022-10-09T15:35:31.523Z  DEBUG controller.provisioning.cloudprovider Discovered launch template Karpenter-karpenter-cluster-9263159034123731516  <span class="o">{</span><span class="s2">"commit"</span>: <span class="s2">"3d87474"</span>, <span class="s2">"provisioner"</span>: <span class="s2">"default"</span><span class="o">}</span>
2022-10-09T15:35:33.829Z  INFO  controller.provisioning.cloudprovider Launched instance: i-0aa11b1f2eb52b92d, <span class="nb">hostname</span>: ip-192-168-32-230.eu-west-1.compute.internal, <span class="nb">type</span>: t3.medium, zone: eu-west-1c, capacityType: spot <span class="o">{</span><span class="s2">"commit"</span>: <span class="s2">"3d87474"</span>, <span class="s2">"provisioner"</span>: <span class="s2">"default"</span><span class="o">}</span>
2022-10-09T15:35:33.837Z  INFO  controller.provisioning Created node with 1 pods requesting <span class="o">{</span><span class="s2">"cpu"</span>:<span class="s2">"1125m"</span>,<span class="s2">"pods"</span>:<span class="s2">"3"</span><span class="o">}</span> from types t4g.micro, t3a.micro, t3.micro, t4g.small, t3a.small and 477 other<span class="o">(</span>s<span class="o">)</span> <span class="o">{</span><span class="s2">"commit"</span>: <span class="s2">"3d87474"</span>, <span class="s2">"provisioner"</span>: <span class="s2">"default"</span><span class="o">}</span>
</code></pre></div></div>

<p>Immediately we can see that there is an additional launched <code class="language-html highlighter-rouge">ip-192-168-32-230.eu-west-1.compute.internal</code> by <code class="language-html highlighter-rouge">karpenter</code></p>

<p><img src="/assets/images/node-provisioning.png" alt="karpenter node provisioning" /></p>

<p>and the pod is running on this node :</p>

<p><img src="/assets/images/pod-running.png" alt="running pods" /></p>

<p>Letâ€™s inspect the node created by the <code class="language-html highlighter-rouge">karpenter</code> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl get node ip-192-168-32-230.eu-west-1.compute.internal <span class="nt">-ojson</span> | jq <span class="nt">-r</span> <span class="s1">'.metadata.labels'</span>
</code></pre></div></div>

<p><img src="/assets/images/explore-provisioned-node.png" alt="exlore provisioned node" /></p>

<p>We can see that itâ€™s a spot instance of type <code class="language-html highlighter-rouge">t3.medium</code>.</p>

<p>By default, <code class="language-html highlighter-rouge">karpenter</code> provisions spot instance, however we can change it to <code class="language-html highlighter-rouge">on-demand</code> instance too based on our requirements. Letâ€™s try to delete the deloyment to see if <code class="language-html highlighter-rouge">karpenter</code> removes the instances.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl delete deployment nginx
</code></pre></div></div>

<p><img src="/assets/images/no-pods.png" alt="no pods" /></p>

<p>and pod is gone, however node is still there :</p>

<p><img src="/assets/images/node-still-there.png" alt="node still there" /></p>

<h3 id="ttlsecondsafterempty">ttlSecondsAfterEmpty</h3>

:ET